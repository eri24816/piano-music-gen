{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 253780 samples from 2570 songs\n"
     ]
    }
   ],
   "source": [
    "from pianogen.dataset.pianorolldataset import PianoRollDataset\n",
    "from pianogen.dataset.tokenized import TokenizedPianoRollDataset\n",
    "from pianogen.tokenizer import PianoRollTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pr_ds = PianoRollDataset(r'W:\\music\\music-data-analysis\\data', max_duration=32*150, segment_len=32, hop_len=32) # 1 bar\n",
    "tokenizer = PianoRollTokenizer(n_pitch=88, n_velocity=32, token_seq_len=120+1)\n",
    "ds = TokenizedPianoRollDataset(pr_ds, tokenizer)\n",
    "dl = DataLoader(ds,batch_size=32, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok so we need a vae, where\n",
    "\n",
    "the encoder is sequence in, embedding out\n",
    "\n",
    "the latent is the embedding\n",
    "\n",
    "the decoder is the embedding in, sequence out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from pianogen.model.model import BinaryPositionalEncoding, SinusoidalPositionalEncoding\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, binary_pe_dim, sinusoidal_pe_dim, max_len):\n",
    "        super().__init__()\n",
    "        self.binary_pos_encoding = BinaryPositionalEncoding(binary_pe_dim, max_len)\n",
    "        self.sinusoidal_pos_encoding = SinusoidalPositionalEncoding(sinusoidal_pe_dim, max_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.binary_pos_encoding(x), self.sinusoidal_pos_encoding(x)*0], dim=-1)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    eats a sequence of tokens, and outputs an embedding at the emb token\n",
    "    no masking\n",
    "    '''\n",
    "    def __init__(self, input_dim, output_dim, feature_dim, max_len, n_heads=8, n_layers=6, ff_dim=1024):\n",
    "        super().__init__()\n",
    "        self.emb_token_idx = input_dim # the last token is the embedding token\n",
    "        self.pe = PositionalEncoding(5, feature_dim//2-5, max_len)\n",
    "        self.emb = nn.Embedding(input_dim+1, feature_dim)\n",
    "        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(feature_dim, n_heads, ff_dim, batch_first=True), n_layers)\n",
    "        self.output_layer = nn.Linear(feature_dim, output_dim*2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, pos: torch.Tensor):\n",
    "        #x: B, L\n",
    "        # add emb token\n",
    "        x = torch.cat([x, torch.zeros(x.shape[0], 1, device=x.device, dtype=torch.long)+self.emb_token_idx], dim=1)\n",
    "        # x: B, L+1\n",
    "\n",
    "        # embed\n",
    "        x = self.emb(x)\n",
    "\n",
    "        # add positional encoding\n",
    "        pe = self.pe(pos)\n",
    "        pe = torch.cat([pe, torch.zeros_like(pe[:,0:1,:])], dim=1) # B, L+1, D\n",
    "        x[:,:,:pe.shape[2]] += pe\n",
    "\n",
    "        x = self.transformer(x)\n",
    "        x = x[:,-1] # get the embedding\n",
    "        x = self.output_layer(x)\n",
    "        mean, logvar = x.chunk(2, dim=1)\n",
    "        logvar = logvar - 6 # make var start small for faster learning\n",
    "        return mean, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    eats an embedding, and outputs a sequence of tokens autoregressively\n",
    "    '''\n",
    "    def __init__(self, input_dim:int, output_dim:int, feature_dim:int, max_len:int, n_heads:int=8, n_layers:int=6, ff_dim:int=1024):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(input_dim, feature_dim)\n",
    "        self.pe = PositionalEncoding(5, feature_dim//2-5, max_len)\n",
    "        self.input_layer = nn.Linear(input_dim*2, feature_dim)\n",
    "        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(feature_dim, n_heads, ff_dim, batch_first=True), n_layers)\n",
    "        self.output_layer = nn.Linear(feature_dim, output_dim)\n",
    "\n",
    "    def forward(self, latent: torch.Tensor, seq: torch.Tensor, pos: torch.Tensor):\n",
    "        #latent: B, D_latent\n",
    "        #seq: B, L\n",
    "        x = self.emb(seq)\n",
    "\n",
    "        # add positional encoding\n",
    "        pe = self.pe(pos)\n",
    "        pe = torch.cat([\n",
    "            pe[:, :-1], # pe of the input tokens\n",
    "            pe[:, 1:]   # pe of the target tokens\n",
    "        ], dim=2) # B, L, D\n",
    "        x = x + pe\n",
    "\n",
    "        # incorporate latent\n",
    "        latent = latent.unsqueeze(1) # B, 1, D\n",
    "        latent = latent.expand(-1, x.shape[1], -1) # B, L, D\n",
    "        x = torch.cat([x, latent], dim=2)\n",
    "        x = self.input_layer(x)\n",
    "\n",
    "        # have to be causal\n",
    "        x = self.transformer.forward(x, mask=nn.Transformer.generate_square_subsequent_mask(x.shape[1]).to(x.device), is_causal=True)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, seq: torch.Tensor, pos: torch.Tensor, return_latent: bool=False):\n",
    "        latent_mean, latent_logvar = self.encoder(seq[:,1:], pos[:,1:])\n",
    "        #latent = self.reparameterize(latent_mean, latent_logvar)\n",
    "        latent = latent_mean\n",
    "        if return_latent:\n",
    "            latent_loss = self.latent_loss(latent_mean, latent_logvar)\n",
    "            return self.decoder(latent, seq[:,:-1], pos), latent, latent_mean, latent_logvar, latent_loss\n",
    "        else:\n",
    "            return self.decoder(latent, seq[:,:-1], pos)\n",
    "        \n",
    "\n",
    "    def reparameterize(self, mean: torch.Tensor, logvar: torch.Tensor):\n",
    "        # mean: B, L\n",
    "        # logvar: B, L\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def latent_loss(self, mean: torch.Tensor, logvar: torch.Tensor):\n",
    "        return torch.mean(-0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp(), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "from typing import Literal\n",
    "from tqdm import tqdm\n",
    "from music_data_analysis.data import Pianoroll\n",
    "from pianogen.gpu_temp_control import GPUTempControl\n",
    "\n",
    "gpu_control = GPUTempControl(64,3)\n",
    "\n",
    "tokenizer: PianoRollTokenizer\n",
    "vae: VAE\n",
    "def inference(latent:torch.Tensor, file_path:str|Path, length:int=120, prompt:Pianoroll|None=None, batch_size:int|None=None,method:Literal['nucleus','top_k']='nucleus', p=0.9, top_k:int=15):\n",
    "    vae.eval()\n",
    "    if prompt is None:\n",
    "        tokens = [{'type':'start'}]\n",
    "    else:\n",
    "        tokens = ds.tokenizer.tokenize(prompt, pad=False)\n",
    "        print('prompt:', tokens[:10])\n",
    "        print('prompt end:', tokens[-10:])\n",
    "\n",
    "    indices = tokenizer.vocab.tokens_to_indices(tokens)\n",
    "    pos = tokenizer.get_frame_indices(tokens, infer_next_frame=True)\n",
    "    indices = indices.unsqueeze(0).to(device)\n",
    "    pos = pos.unsqueeze(0).to(device)\n",
    "\n",
    "    last_token = tokens[-1]\n",
    "\n",
    "    for _ in tqdm(range(length-len(tokens))):\n",
    "        gpu_control.cooldown()\n",
    "\n",
    "        logits = vae.decoder(latent, indices, pos).squeeze(0)[-1].detach().cpu()\n",
    "        new_token = tokenizer.sample_from_logits(logits, last_token, method=method, p=p, top_k=top_k)\n",
    "        tokens.append(new_token)\n",
    "        last_token = new_token\n",
    "\n",
    "        # update indices and pos\n",
    "\n",
    "        new_token_idx = tokenizer.vocab.get_idx(new_token)\n",
    "        indices = torch.cat([indices, torch.tensor([[new_token_idx]]).to(device)], dim=-1)\n",
    "        if new_token['type'] == 'next_frame':\n",
    "            new_pos = pos[0,-1] + 1\n",
    "        else:\n",
    "            new_pos = pos[0,-1]\n",
    "        pos = torch.cat([pos, torch.tensor([[new_pos]]).to(device)], dim=-1)\n",
    "\n",
    "        if new_token['type'] == 'end':\n",
    "            break\n",
    "\n",
    "    pr = tokenizer.detokenize(tokens).slice(0,32)\n",
    "    pr.to_midi(file_path)\n",
    "    print(len(tokens),' tokens :', tokens[:10])\n",
    "    return pr\n",
    "\n",
    "def gaussian_pdf(mean, var, x):\n",
    "    result = torch.exp(-0.5 * (x-mean).pow(2) / var) / torch.sqrt(2 * torch.pi * var)\n",
    "    return result.prod(dim=-1)\n",
    "\n",
    "def log_gaussian_pdf(mean, var, x):\n",
    "    result = torch.exp(-0.5 * (x-mean).pow(2) / var) / torch.sqrt(2 * torch.pi * var)\n",
    "    return result.log().sum(dim=-1)\n",
    "\n",
    "def get_confidence(mean, var):\n",
    "    B = mean.shape[0]\n",
    "    s = 0\n",
    "    n=64\n",
    "    for _ in range(n):\n",
    "        i = random.randint(0,B-1)\n",
    "        j = random.randint(0,B-1)\n",
    "        if i==j:\n",
    "            j = (j+1)%B\n",
    "        log_p1 = log_gaussian_pdf(mean[i], var[i], mean[i])\n",
    "        log_p2 = log_gaussian_pdf(mean[j], var[j], mean[i])\n",
    "        log_p2 -= log_p1\n",
    "        log_p1 -= log_p1\n",
    "        p1 = log_p1.exp()\n",
    "        p2 = log_p2.exp()\n",
    "        s += p1/(p1+p2)\n",
    "    return s/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 7.500156 M\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "exp_name = 'vae/1002_lr2e-4'\n",
    "device = 'cuda'\n",
    "\n",
    "output_dir = Path(f'./output/{exp_name}')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "checkpoint_dir = Path(f'./checkpoint/{exp_name}')\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "tensorboard_dir = Path(f'./tensorboard/{exp_name}')\n",
    "\n",
    "\n",
    "encoder = Encoder(input_dim=len(tokenizer.vocab), output_dim=256, feature_dim=256, max_len=120, n_heads=8, n_layers=3, ff_dim=1024)\n",
    "decoder = Decoder(input_dim=256, output_dim=len(tokenizer.vocab), feature_dim=256, max_len=120, n_heads=8, n_layers=6, ff_dim=1024)\n",
    "vae = VAE(encoder, decoder)\n",
    "crit = nn.CrossEntropyLoss(ignore_index=0)\n",
    "opt = torch.optim.Adam(vae.parameters(),lr=2e-4)\n",
    "\n",
    "writer = SummaryWriter(tensorboard_dir)\n",
    "\n",
    "print('number of parameters:', sum(p.numel() for p in vae.parameters())/1e6, 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_epoch = 0\n",
    "epoch = from_epoch\n",
    "# load from checkpoint\n",
    "if from_epoch > 0:\n",
    "    checkpoint = torch.load(checkpoint_dir/f'{from_epoch}.pt')\n",
    "    vae.load_state_dict(checkpoint['model'])\n",
    "    opt.load_state_dict(checkpoint['opt'])\n",
    "vae = vae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7931 [00:00<?, ?it/s]c:\\Users\\User\\miniconda3\\envs\\gr\\Lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "100%|██████████| 119/119 [00:00<00:00, 127.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 48, 'type': 'pitch'}, {'value': 9, 'type': 'velocity'}, {'value': 8, 'type': 'pitch'}, {'value': 23, 'type': 'velocity'}, {'value': 27, 'type': 'pitch'}, {'value': 16, 'type': 'velocity'}, {'value': 24, 'type': 'pitch'}, {'value': 13, 'type': 'velocity'}, {'value': 24, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 139.82it/s]\n",
      "  0%|          | 2/7931 [00:21<19:19:44,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'type': 'next_frame'}, {'value': 79, 'type': 'pitch'}, {'value': 25, 'type': 'velocity'}, {'value': 53, 'type': 'pitch'}, {'value': 23, 'type': 'velocity'}, {'type': 'next_frame'}, {'value': 37, 'type': 'pitch'}, {'value': 25, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:01<00:00, 114.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 14, 'type': 'pitch'}, {'value': 18, 'type': 'velocity'}, {'value': 22, 'type': 'pitch'}, {'value': 17, 'type': 'velocity'}, {'value': 34, 'type': 'pitch'}, {'value': 17, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 24, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 129.90it/s]\n",
      "  6%|▋         | 503/7931 [01:20<36:58,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 22, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 29, 'type': 'pitch'}, {'value': 18, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 121.66it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 55, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'value': 63, 'type': 'pitch'}, {'value': 24, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 12, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 120.92it/s]\n",
      " 13%|█▎        | 1002/7931 [02:22<50:19,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 36, 'type': 'pitch'}, {'value': 10, 'type': 'velocity'}, {'value': 43, 'type': 'pitch'}, {'value': 13, 'type': 'velocity'}, {'value': 48, 'type': 'pitch'}, {'value': 11, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:01<00:00, 116.42it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 8, 'type': 'pitch'}, {'value': 22, 'type': 'velocity'}, {'value': 20, 'type': 'pitch'}, {'value': 22, 'type': 'velocity'}, {'value': 55, 'type': 'pitch'}, {'value': 23, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 122.85it/s]\n",
      " 19%|█▉        | 1503/7931 [03:24<34:34,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 38, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 123.42it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 22, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'value': 34, 'type': 'pitch'}, {'value': 18, 'type': 'velocity'}, {'value': 38, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'value': 41, 'type': 'pitch'}, {'value': 23, 'type': 'velocity'}, {'value': 44, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:01<00:00, 115.63it/s]\n",
      " 25%|██▌       | 2003/7931 [04:26<29:17,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 31, 'type': 'pitch'}, {'value': 11, 'type': 'velocity'}, {'value': 42, 'type': 'pitch'}, {'value': 7, 'type': 'velocity'}, {'value': 42, 'type': 'pitch'}, {'value': 11, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 45, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 121.78it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 46, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 131.55it/s]\n",
      " 32%|███▏      | 2503/7931 [05:27<27:24,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 56, 'type': 'pitch'}, {'value': 14, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 44, 'type': 'pitch'}, {'value': 11, 'type': 'velocity'}, {'type': 'next_frame'}, {'value': 51, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 123.68it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 60, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 38, 'type': 'pitch'}, {'value': 17, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 139.00it/s]\n",
      " 38%|███▊      | 3003/7931 [06:29<26:24,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 20, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'value': 32, 'type': 'pitch'}, {'value': 18, 'type': 'velocity'}, {'value': 56, 'type': 'pitch'}, {'value': 18, 'type': 'velocity'}, {'value': 60, 'type': 'pitch'}, {'value': 24, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:01<00:00, 114.85it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 20, 'type': 'pitch'}, {'value': 15, 'type': 'velocity'}, {'value': 27, 'type': 'pitch'}, {'value': 10, 'type': 'velocity'}, {'value': 39, 'type': 'pitch'}, {'value': 9, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 131.40it/s]\n",
      " 44%|████▍     | 3503/7931 [07:31<26:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 7, 'type': 'pitch'}, {'value': 19, 'type': 'velocity'}, {'value': 19, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 43, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 120.18it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 19, 'type': 'pitch'}, {'value': 22, 'type': 'velocity'}, {'value': 31, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'value': 34, 'type': 'pitch'}, {'value': 23, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 123.62it/s]\n",
      " 50%|█████     | 4003/7931 [08:33<22:36,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 17, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'value': 44, 'type': 'pitch'}, {'value': 22, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 24, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:01<00:00, 118.39it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 17, 'type': 'pitch'}, {'value': 17, 'type': 'velocity'}, {'value': 39, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'value': 43, 'type': 'pitch'}, {'value': 19, 'type': 'velocity'}, {'value': 44, 'type': 'pitch'}, {'value': 18, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:01<00:00, 116.88it/s]\n",
      " 57%|█████▋    | 4503/7931 [09:35<17:07,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 34, 'type': 'pitch'}, {'value': 16, 'type': 'velocity'}, {'value': 46, 'type': 'pitch'}, {'value': 19, 'type': 'velocity'}, {'value': 60, 'type': 'pitch'}, {'value': 22, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:01<00:00, 115.23it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 19, 'type': 'pitch'}, {'value': 13, 'type': 'velocity'}, {'value': 52, 'type': 'pitch'}, {'value': 19, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 34, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 130.82it/s]\n",
      " 63%|██████▎   | 5002/7931 [10:37<20:53,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 48, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'value': 60, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 55, 'type': 'pitch'}, {'value': 19, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 119.40it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 20, 'type': 'pitch'}, {'value': 19, 'type': 'velocity'}, {'value': 32, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'value': 36, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'value': 38, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 122.04it/s]\n",
      " 69%|██████▉   | 5504/7931 [11:39<12:21,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 27, 'type': 'pitch'}, {'value': 14, 'type': 'velocity'}, {'value': 51, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'value': 55, 'type': 'pitch'}, {'value': 16, 'type': 'velocity'}, {'value': 60, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'value': 63, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:01<00:00, 118.04it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 19, 'type': 'pitch'}, {'value': 17, 'type': 'velocity'}, {'value': 24, 'type': 'pitch'}, {'value': 18, 'type': 'velocity'}, {'value': 31, 'type': 'pitch'}, {'value': 17, 'type': 'velocity'}, {'value': 41, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 125.05it/s]\n",
      " 76%|███████▌  | 6003/7931 [12:41<10:40,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 24, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'value': 36, 'type': 'pitch'}, {'value': 22, 'type': 'velocity'}, {'value': 55, 'type': 'pitch'}, {'value': 19, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:01<00:00, 110.78it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 15, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'value': 22, 'type': 'pitch'}, {'value': 18, 'type': 'velocity'}, {'value': 20, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 136.69it/s]\n",
      " 82%|████████▏ | 6503/7931 [13:42<07:42,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 24, 'type': 'pitch'}, {'value': 22, 'type': 'velocity'}, {'value': 48, 'type': 'pitch'}, {'value': 24, 'type': 'velocity'}, {'value': 51, 'type': 'pitch'}, {'value': 23, 'type': 'velocity'}, {'value': 55, 'type': 'pitch'}, {'value': 23, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 119.50it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 20, 'type': 'pitch'}, {'value': 24, 'type': 'velocity'}, {'value': 32, 'type': 'pitch'}, {'value': 26, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 68, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:01<00:00, 115.74it/s]\n",
      " 88%|████████▊ | 7003/7931 [14:44<05:24,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  tokens : [{'type': 'start'}, {'value': 27, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'value': 55, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'value': 63, 'type': 'pitch'}, {'value': 22, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 7179/7931 [15:05<01:34,  7.93it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(from_epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m12\u001b[39m):\n\u001b[0;32m     13\u001b[0m     tq \u001b[38;5;241m=\u001b[39m tqdm(dl)\n\u001b[1;32m---> 14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mB\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\gr\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\gr\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\gr\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\gr\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\gr\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\gr\\Lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\gr\\Lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\gr\\Lib\\multiprocessing\\connection.py:346\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    344\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\gr\\Lib\\multiprocessing\\connection.py:896\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    893\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    894\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 896\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\gr\\Lib\\multiprocessing\\connection.py:828\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    826\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 828\u001b[0m     res \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWaitForMultipleObjects(L, \u001b[38;5;28;01mFalse\u001b[39;00m, timeout)\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    830\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "import random\n",
    "from pianogen import gpu_temp_control\n",
    "from tqdm import tqdm\n",
    "temp_control = gpu_temp_control.GPUTempControl(64,3)\n",
    "\n",
    "vae.to(device)\n",
    "crit.to(device)\n",
    "\n",
    "vae.train()\n",
    "\n",
    "for epoch in range(from_epoch+1,12):\n",
    "    tq = tqdm(dl)\n",
    "    for i, batch in enumerate(tq):\n",
    "        B = batch['indices'].shape[0]\n",
    "        batch = {k:v.to(device) if isinstance(v, torch.Tensor) else v for k,v in batch.items()}\n",
    "        opt.zero_grad()\n",
    "        reconst, latent, latent_mean, latent_logvar, latent_loss = vae(batch['indices'], batch['pos'], return_latent = True)\n",
    "        reconst_loss = crit((reconst+batch['output_mask']).transpose(1,2), batch['indices'][:,1:])\n",
    "        loss = reconst_loss + latent_loss*0\n",
    "\n",
    "        latent.retain_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        temp_control.cooldown()\n",
    "                    \n",
    "        if torch.isnan(loss):\n",
    "            raise ValueError(\"Loss is NaN\")\n",
    "\n",
    "        writer.add_scalar('loss', loss.item(), epoch*len(dl)+i)\n",
    "        writer.add_scalar('latent_loss', latent_loss.item(), epoch*len(dl)+i)\n",
    "        writer.add_scalar('reconst_loss', reconst_loss.item(), epoch*len(dl)+i)\n",
    "        writer.add_scalar('gpu_temp', temp_control.get_temp(), epoch*len(dl)+i)\n",
    "        if i % 100 == 0:\n",
    "            accuracy = ((reconst.argmax(dim=-1) == batch['indices'][:,1:])[batch['indices'][:,1:]>0]).float().mean().item()\n",
    "            writer.add_scalar('accuracy', accuracy, epoch*len(dl)+i)\n",
    "\n",
    "            latent_samples = []\n",
    "            for _ in range(10):\n",
    "                latent_samples.append(vae.reparameterize(latent_mean, latent_logvar))\n",
    "            latent_samples = torch.cat(latent_samples, dim=0) # sample, B, 3\n",
    "            latent_samples = latent_samples.transpose(0,1).contiguous().view(B*10, -1) # B*sample, 3\n",
    "            writer.add_embedding(tag='latent_samples',mat=latent_samples, metadata=[i for i in range(B) for _ in range(10)],global_step=epoch*len(dl)+i)\n",
    "            writer.add_scalar('confidence', get_confidence(latent_mean, latent_logvar.exp()), epoch*len(dl)+i)\n",
    "            writer.add_scalar('latent_grad', latent.grad.norm(1).mean().item(), epoch*len(dl)+i)\n",
    "            \n",
    "        if i % 500 == 0:\n",
    "            pr = inference(torch.randn(1, 256).to(device), output_dir/f'{epoch}_{i}_random.mid', length=120)\n",
    "            writer.add_image('random', pr.to_tensor(start_time=0,end_time=32,padding=True).transpose(0,1).flip(0)/127, epoch*len(dl)+i,dataformats='HW')\n",
    "            \n",
    "            latent_mean, _ = vae.encoder.forward(batch['indices'][0:1,:-1], batch['pos'][0:1, :-1]) # use one sample from the batch as gt\n",
    "            pr = inference(latent_mean, output_dir/f'{epoch}_{i}_reconstruct.mid', length=120)\n",
    "            gt_pr = tokenizer.detokenize(tokenizer.idx_to_token_seq(batch['indices'][0].cpu().numpy()))\n",
    "            \n",
    "            writer.add_image('reconstruct', torch.cat([\n",
    "                pr.to_tensor(start_time=0,end_time=32,padding=True).transpose(0,1).flip(0)/127,\n",
    "                gt_pr.to_tensor(start_time=0,end_time=32,padding=True).transpose(0,1).flip(0)/127\n",
    "            ], dim=1), epoch*len(dl)+i,dataformats='HW')\n",
    "\n",
    "            \n",
    "            \n",
    "            gt_pr.to_midi(output_dir/f'{epoch}_{i}_gt.mid')\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        torch.save({'model':vae.state_dict(), 'opt':opt.state_dict()}, checkpoint_dir/f'{epoch}.pt')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 120.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'value': 48, 'type': 'pitch'}, {'value': 17, 'type': 'velocity'}, {'value': 50, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 43, 'type': 'pitch'}, {'value': 22, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 122.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'value': 48, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 56, 'type': 'pitch'}, {'value': 22, 'type': 'velocity'}, {'value': 55, 'type': 'pitch'}, {'value': 19, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ticks per beat: 480\n",
       "max tick: 0\n",
       "tempo changes: 1\n",
       "time sig: 0\n",
       "key sig: 0\n",
       "markers: 0\n",
       "lyrics: False\n",
       "instruments: 1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 103\n",
    "pr = inference(torch.randn(1, 256).to(device), output_dir/f'{epoch}_{i}_random.mid', length=120)\n",
    "writer.add_image('random', pr.to_tensor(start_time=0,end_time=32,padding=True).transpose(0,1).flip(0)/127, epoch*len(dl)+i,dataformats='HW')\n",
    "\n",
    "latent_mean, _ = vae.encoder.forward(batch['indices'][0:1,:-1], batch['pos'][0:1]) # use one sample from the batch as gt\n",
    "pr = inference(latent_mean, output_dir/f'{epoch}_{i}_reconstruct.mid', length=120)\n",
    "gt_pr = tokenizer.detokenize(tokenizer.idx_to_token_seq(batch['indices'][0].cpu().numpy()))\n",
    "\n",
    "writer.add_image('reconstruct', torch.cat([\n",
    "    pr.to_tensor(start_time=0,end_time=32,padding=True).transpose(0,1).flip(0)/127,\n",
    "    gt_pr.to_tensor(start_time=0,end_time=32,padding=True).transpose(0,1).flip(0)/127\n",
    "], dim=1), epoch*len(dl)+i,dataformats='HW')\n",
    "\n",
    "gt_pr.to_midi(output_dir/f'{epoch}_{i}_gt.mid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -7.7109,  -8.2419,  -7.6864,  ...,  -4.2910,  -4.3220, -10.3268],\n",
       "        [ -7.7109,  -8.2421,  -7.6865,  ...,  -4.2912,  -4.3219, -10.3270],\n",
       "        [ -7.7109,  -8.2418,  -7.6864,  ...,  -4.2912,  -4.3220, -10.3269],\n",
       "        ...,\n",
       "        [ -7.7109,  -8.2417,  -7.6865,  ...,  -4.2916,  -4.3217, -10.3270],\n",
       "        [ -7.7110,  -8.2419,  -7.6863,  ...,  -4.2910,  -4.3220, -10.3267],\n",
       "        [ -7.7109,  -8.2416,  -7.6866,  ...,  -4.2917,  -4.3214, -10.3270]],\n",
       "       device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_logvar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.to('cuda')\n",
    "reconst, latent, latent_mean, latent_logvar, latent_loss = vae(batch['indices'], batch['pos'], return_latent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Note(0,48,60,None),\n",
       " Note(0,60,76,None),\n",
       " Note(0,67,68,None),\n",
       " Note(0,72,84,None),\n",
       " Note(4,55,60,None),\n",
       " Note(4,72,88,None),\n",
       " Note(8,60,64,None),\n",
       " Note(12,48,52,None),\n",
       " Note(16,52,60,None),\n",
       " Note(20,48,48,None),\n",
       " Note(20,52,64,None),\n",
       " Note(24,60,80,None),\n",
       " Note(24,72,80,None),\n",
       " Note(28,48,56,None),\n",
       " Note(32,52,48,None),\n",
       " Note(36,55,60,None),\n",
       " Note(40,60,80,None),\n",
       " Note(40,71,80,None),\n",
       " Note(44,48,68,None),\n",
       " Note(44,72,92,None),\n",
       " Note(48,48,52,None),\n",
       " Note(48,64,72,None),\n",
       " Note(52,47,60,None),\n",
       " Note(52,52,60,None),\n",
       " Note(56,40,56,None),\n",
       " Note(60,52,68,None),\n",
       " Note(64,57,64,None)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.detokenize(tokens).notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 142.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'value': 8, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'value': 20, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a80b375910>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tokens, pr = inference(torch.randn(1, 256).to(device), output_dir/f'{epoch}_{i}_random.mid', length=120)\n",
    "plt.imshow(pr.to_tensor(start_time=0,end_time=32,padding=True).transpose(0,1).flip(0)/127)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'start'},\n",
       " {'value': 27, 'type': 'pitch'},\n",
       " {'value': 15, 'type': 'velocity'},\n",
       " {'value': 39, 'type': 'pitch'},\n",
       " {'value': 19, 'type': 'velocity'},\n",
       " {'value': 46, 'type': 'pitch'},\n",
       " {'value': 17, 'type': 'velocity'},\n",
       " {'value': 51, 'type': 'pitch'},\n",
       " {'value': 21, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 34, 'type': 'pitch'},\n",
       " {'value': 15, 'type': 'velocity'},\n",
       " {'value': 51, 'type': 'pitch'},\n",
       " {'value': 22, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 39, 'type': 'pitch'},\n",
       " {'value': 16, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 27, 'type': 'pitch'},\n",
       " {'value': 13, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 31, 'type': 'pitch'},\n",
       " {'value': 15, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 27, 'type': 'pitch'},\n",
       " {'value': 12, 'type': 'velocity'},\n",
       " {'value': 31, 'type': 'pitch'},\n",
       " {'value': 16, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 39, 'type': 'pitch'},\n",
       " {'value': 20, 'type': 'velocity'},\n",
       " {'value': 51, 'type': 'pitch'},\n",
       " {'value': 20, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 27, 'type': 'pitch'},\n",
       " {'value': 14, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 31, 'type': 'pitch'},\n",
       " {'value': 12, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 34, 'type': 'pitch'},\n",
       " {'value': 15, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 39, 'type': 'pitch'},\n",
       " {'value': 20, 'type': 'velocity'},\n",
       " {'value': 50, 'type': 'pitch'},\n",
       " {'value': 20, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 27, 'type': 'pitch'},\n",
       " {'value': 17, 'type': 'velocity'},\n",
       " {'value': 51, 'type': 'pitch'},\n",
       " {'value': 23, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 27, 'type': 'pitch'},\n",
       " {'value': 13, 'type': 'velocity'},\n",
       " {'value': 43, 'type': 'pitch'},\n",
       " {'value': 18, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 26, 'type': 'pitch'},\n",
       " {'value': 15, 'type': 'velocity'},\n",
       " {'value': 31, 'type': 'pitch'},\n",
       " {'value': 15, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 19, 'type': 'pitch'},\n",
       " {'value': 14, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 31, 'type': 'pitch'},\n",
       " {'value': 17, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 36, 'type': 'pitch'},\n",
       " {'value': 16, 'type': 'velocity'},\n",
       " {'value': 51, 'type': 'pitch'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8808)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.zeros(2,2000)\n",
    "var = torch.ones(2,2000)\n",
    "mean[0,0] += 2\n",
    "get_confidence(mean, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_confidence(latent_mean*500, latent_logvar.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'start'},\n",
       " {'value': 17, 'type': 'pitch'},\n",
       " {'value': 20, 'type': 'velocity'},\n",
       " {'value': 43, 'type': 'pitch'},\n",
       " {'value': 20, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 24, 'type': 'pitch'},\n",
       " {'value': 17, 'type': 'velocity'},\n",
       " {'value': 36, 'type': 'pitch'},\n",
       " {'value': 20, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 29, 'type': 'pitch'},\n",
       " {'value': 20, 'type': 'velocity'},\n",
       " {'value': 46, 'type': 'pitch'},\n",
       " {'value': 22, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 46, 'type': 'pitch'},\n",
       " {'value': 20, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 46, 'type': 'pitch'},\n",
       " {'value': 21, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 46, 'type': 'pitch'},\n",
       " {'value': 22, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 29, 'type': 'pitch'},\n",
       " {'value': 19, 'type': 'velocity'},\n",
       " {'value': 48, 'type': 'pitch'},\n",
       " {'value': 21, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'value': 43, 'type': 'pitch'},\n",
       " {'value': 20, 'type': 'velocity'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'next_frame'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'},\n",
       " {'type': 'pad'}]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.idx_to_token_seq(batch['indices'][0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
