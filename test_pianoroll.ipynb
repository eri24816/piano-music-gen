{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from local_attention import LocalAttention\n",
    "from pianogen.pe import binary_positional_encoding, sinusoidal_positional_encoding\n",
    "\n",
    "class BinaryPositionalEncoding(nn.Module):\n",
    "    '''\n",
    "    Input: B, L (long)\n",
    "    Output: B, L, D\n",
    "    '''\n",
    "    def __init__(self, dim:int, max_len:int):\n",
    "        super().__init__()\n",
    "        self.register_buffer('pos_encoding', binary_positional_encoding(max_len, dim).unsqueeze(0))\n",
    "\n",
    "    def forward(self, pos: torch.Tensor):\n",
    "        return torch.gather(self.pos_encoding.expand(pos.shape[0], -1, -1), 1, pos.unsqueeze(-1).expand(-1, -1, self.pos_encoding.shape[-1]))\n",
    "    \n",
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    '''\n",
    "    Input: B, L (long)\n",
    "    Output: B, L, D\n",
    "    '''\n",
    "    def __init__(self, dim:int, max_len:int):\n",
    "        super().__init__()\n",
    "        self.register_buffer('pos_encoding', sinusoidal_positional_encoding(max_len, dim).unsqueeze(0))\n",
    "\n",
    "    def forward(self, pos: torch.Tensor):\n",
    "        return torch.gather(self.pos_encoding.expand(pos.shape[0], -1, -1), 1, pos.unsqueeze(-1).expand(-1, -1, self.pos_encoding.shape[-1]))\n",
    "    \n",
    "class LocalMultiHeadAttention(nn.Module):\n",
    "    '''\n",
    "    Input: B, L, D\n",
    "    Output: B, L, D\n",
    "    '''\n",
    "    def __init__(self, heads, dim, window_size, causal = False, dropout = 0.):\n",
    "        super().__init__()\n",
    "        assert dim % heads == 0, 'dimension must be divisible by number of heads'\n",
    "        self.heads = heads\n",
    "        self.to_qkv = nn.Linear(dim, dim * 3, bias = False)\n",
    "        self.local_attn = LocalAttention(dim = dim // heads, window_size = window_size, causal = causal, dropout = dropout, autopad=True)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        B, L, D = x.shape\n",
    "        H = self.heads\n",
    "        E = D // H\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1) # B, L, 3 * H, E\n",
    "        q, k, v = map(lambda t: t.view(B, L, H, E).transpose(1, 2), qkv)\n",
    "\n",
    "        out = self.local_attn(q, k, v, mask = mask)\n",
    "        out = out.transpose(1, 2).reshape(B, L, D)\n",
    "        return out\n",
    "\n",
    "class LMHATransformerBlock(nn.Module):\n",
    "    '''\n",
    "    Input: B, L, D\n",
    "    Output: B, L, D\n",
    "    '''\n",
    "    def __init__(self, dim, heads, window_size, dim_feedforward, dropout = 0., causal = False):\n",
    "        super().__init__()\n",
    "        self.attn = LocalMultiHeadAttention(heads = heads, dim = dim, window_size = window_size, dropout = dropout, causal = causal)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(dim, dim_feedforward),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(dim_feedforward, dim)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        x = x + self.dropout(self.attn(self.norm1(x), mask = mask))\n",
    "        x = x + self.dropout(self.ff(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "class SelectiveAttnTransformer(nn.Module):\n",
    "    '''\n",
    "    Token level attention is too expensive to apply on the whole sequence. This module instead learns a regular attention mask with\n",
    "    a downsampled sequence (segment level), then transform it into the mask for the token level attention, by sparsely select the\n",
    "    most important segments (the selection is not differentiable though).\n",
    "\n",
    "    As such, token level attention is only applied on the selected segments, which is much faster.\n",
    "\n",
    "    Input: B, n_token, n_feature\n",
    "    '''\n",
    "\n",
    "    def __init__(self, vocab_size, segment_len, dim = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.segment_len = segment_len\n",
    "        self._downsampled_path_enabled = True\n",
    "\n",
    "        self.binary_pe_dim = 5\n",
    "        self.sinusoidal_pe_dim = 123\n",
    "        self.token_embedding = nn.Embedding(vocab_size, dim)\n",
    "        self.binary_pos_encoding = BinaryPositionalEncoding(self.binary_pe_dim, 10240)\n",
    "        self.sinusoidal_pos_encoding = SinusoidalPositionalEncoding(self.sinusoidal_pe_dim, 10240)\n",
    "\n",
    "        self.in_local_attention = nn.Sequential(*[\n",
    "            LMHATransformerBlock(heads=8, dim=dim, window_size=200, causal=True, dropout=0.1, dim_feedforward=1024) for _ in range(2)\n",
    "        ])\n",
    "        self.downsample = nn.AvgPool1d(segment_len, stride=segment_len)\n",
    "        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=dim, nhead=8, dim_feedforward=1024, batch_first=True), num_layers=4)\n",
    "        self.upsample = nn.Upsample(scale_factor=segment_len, mode='nearest')\n",
    "        self.out_local_attention = nn.Sequential(*[\n",
    "            LMHATransformerBlock(heads=8, dim=dim, window_size=200, causal=True, dropout=0.1, dim_feedforward=1024) for _ in range(2)\n",
    "        ])\n",
    "        self.out_linear = nn.Linear(dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, pos):\n",
    "        B, L = x.shape\n",
    "        # x: B, L\n",
    "        # pos: B, L+1\n",
    "        x = self.token_embedding(x)\n",
    "\n",
    "        pe = torch.cat([\n",
    "            self.binary_pos_encoding(pos),\n",
    "            self.sinusoidal_pos_encoding(pos),\n",
    "        ], dim=-1) # B, L+1, D/2\n",
    "\n",
    "        pe = torch.cat([\n",
    "            pe[:, :-1], # pe of the input tokens\n",
    "            pe[:, 1:]   # pe of the target tokens\n",
    "        ], dim=2) # B, L, D\n",
    "\n",
    "        x = x + pe\n",
    "        \n",
    "        \n",
    "        x = self.in_local_attention(x)\n",
    "        before_down = x\n",
    "\n",
    "        # before entering the downsampled path, we need to make L % segment_len == 0\n",
    "\n",
    "        if L >= self.segment_len and self._downsampled_path_enabled: # if L < segment_len, we don't need to downsample\n",
    "\n",
    "            x = x[:, :L - (L % self.segment_len)] # B, L - (L % segment_len), D\n",
    "\n",
    "            x = self.downsample(x.transpose(1, 2)).transpose(1, 2)\n",
    "            x = self.transformer(x)\n",
    "            x = self.upsample(x.transpose(1, 2)).transpose(1, 2) # B, L - (L % segment_len), D\n",
    "\n",
    "            # to avoid information leak, shift the data from the downsampled path right by segment_len-1\n",
    "            x = F.pad(x, (0,0,self.segment_len-1, 0), 'constant', 0) # B, L+self.segment_len-1-(L % self.segment_len), D\n",
    "            # crop redundant right-most stuff due to the right shift\n",
    "            x = x[:, :L] # B, L, D\n",
    "            # skip connection\n",
    "            x = x + before_down\n",
    "\n",
    "        x = self.out_local_attention(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.out_linear(x)\n",
    "        return x\n",
    "    \n",
    "    def set_downsampled_path_enabled(self, enabled):\n",
    "        self._downsampled_path_enabled = enabled\n",
    "\n",
    "class PianoRollGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_linear = nn.Linear(200, 256)\n",
    "        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=256, nhead=8, dim_feedforward=1024, batch_first=True), num_layers=6)\n",
    "        self.out_linear = nn.Linear(256, 121)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_linear(x)\n",
    "        x = self.transformer(x, mask = nn.Transformer.generate_square_subsequent_mask(x.shape[1]).to(x.device), is_causal = True)\n",
    "        x = self.out_linear(x)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2368 samples from 2570 songs\n"
     ]
    }
   ],
   "source": [
    "from pianogen.dataset.pianorolldataset import PianoRollDataset\n",
    "from pianogen.dataset.tokenized import TokenizedPianoRollDataset\n",
    "from pianogen.tokenizer import PianoRollTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pr_ds = PianoRollDataset(r'W:\\music\\music-data-analysis\\data', max_duration=32*150) # 150 bars\n",
    "tokenizer = PianoRollTokenizer(n_pitch=88, n_velocity=32, token_seq_len=10240+1)\n",
    "ds = TokenizedPianoRollDataset(pr_ds, tokenizer)\n",
    "dl = DataLoader(ds,batch_size=8, shuffle=True, num_workers=8)\n",
    "\n",
    "\n",
    "# pr_ds = PianoRollDataset('data', segment_len=32*4, hop_len=32*4) # 4 bars\n",
    "# tokenizer = PianoRollTokenizer(n_pitch=88, n_velocity=32, token_seq_len=600+1)\n",
    "# ds = TokenizedPianoRollDataset(pr_ds, tokenizer)\n",
    "# dl = DataLoader(ds,batch_size=32, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Em',\n",
       " 'Em7',\n",
       " 'C',\n",
       " 'G',\n",
       " 'F',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'Dm',\n",
       " 'Dm',\n",
       " 'A#M7',\n",
       " 'C',\n",
       " 'Dm7',\n",
       " 'C',\n",
       " 'Am',\n",
       " 'Gm7',\n",
       " 'C',\n",
       " 'Dm',\n",
       " 'A#M7',\n",
       " 'C',\n",
       " 'Dm7',\n",
       " 'C',\n",
       " 'Am',\n",
       " 'D7',\n",
       " 'Em7',\n",
       " 'Gm7',\n",
       " 'C',\n",
       " 'A#M7',\n",
       " 'F7',\n",
       " 'A#M7',\n",
       " 'F',\n",
       " 'A#M7',\n",
       " 'F',\n",
       " 'A#M7',\n",
       " 'Dm7',\n",
       " 'Dm',\n",
       " 'G7',\n",
       " 'Am',\n",
       " 'G',\n",
       " 'C',\n",
       " 'C',\n",
       " 'Dm',\n",
       " 'E',\n",
       " 'Am',\n",
       " 'G',\n",
       " 'F',\n",
       " 'E',\n",
       " 'AM7',\n",
       " 'Am',\n",
       " 'F',\n",
       " 'Dm',\n",
       " 'Em',\n",
       " 'E7',\n",
       " 'Am',\n",
       " 'G',\n",
       " 'C',\n",
       " 'C',\n",
       " 'Dm',\n",
       " 'E',\n",
       " 'Am',\n",
       " 'C',\n",
       " 'F',\n",
       " 'E',\n",
       " 'Am',\n",
       " 'Am',\n",
       " 'F',\n",
       " 'Dm',\n",
       " 'E7',\n",
       " 'E7',\n",
       " 'C',\n",
       " 'G',\n",
       " 'F',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'Em',\n",
       " 'Em7',\n",
       " 'C',\n",
       " 'G',\n",
       " 'F',\n",
       " 'C']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pr_ds.get_sample(500)\n",
    "sample.song.read_json(\"chords\")[sample.start // 16 : sample.end // 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "from music_data_analysis.data import PianoRoll\n",
    "from pianogen.gpu_temp_control import GPUTempControl\n",
    "\n",
    "gpu_control = GPUTempControl(64,3)\n",
    "\n",
    "tokenizer: PianoRollTokenizer\n",
    "model: SelectiveAttnTransformer\n",
    "def inference(file_path:str, length:int=512, prompt:PianoRoll|None=None, batch_size:int|None=None):\n",
    "    model.eval()\n",
    "    if prompt is None:\n",
    "        tokens = [{'type':'start'}]\n",
    "    else:\n",
    "        tokens = ds.tokenizer.tokenize(prompt, pad=False)\n",
    "        print('prompt:', tokens[:10])\n",
    "\n",
    "    indices = tokenizer.vocab.tokens_to_indices(tokens)\n",
    "    pos = tokenizer.get_frame_indices(tokens, infer_next_frame=True)\n",
    "    indices = indices.unsqueeze(0).to(device)\n",
    "    pos = pos.unsqueeze(0).to(device)\n",
    "\n",
    "    last_token = tokens[-1]\n",
    "\n",
    "    for _ in tqdm(range(length - len(tokens))):\n",
    "        gpu_control.cooldown()\n",
    "\n",
    "        logits = model(indices,pos).squeeze(0)[-1].detach().cpu()\n",
    "        new_token = tokenizer.sample_from_logits(logits, last_token)\n",
    "        tokens.append(new_token)\n",
    "        last_token = new_token\n",
    "\n",
    "        # update indices and pos\n",
    "\n",
    "        new_token_idx = tokenizer.vocab.get_idx(new_token)\n",
    "        indices = torch.cat([indices, torch.tensor([[new_token_idx]]).to(device)], dim=-1)\n",
    "        if new_token['type'] == 'next_frame':\n",
    "            new_pos = pos[0,-1] + 1\n",
    "        else:\n",
    "            new_pos = pos[0,-1]\n",
    "        pos = torch.cat([pos, torch.tensor([[new_pos]]).to(device)], dim=-1)\n",
    "\n",
    "        if new_token['type'] == 'end':\n",
    "            break\n",
    "\n",
    "    tokenizer.detokenize(tokens).to_midi(file_path)\n",
    "    print('result:', tokens[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 6.115452 M\n"
     ]
    }
   ],
   "source": [
    "model = SelectiveAttnTransformer(len(tokenizer.vocab),128,256)\n",
    "crit = nn.CrossEntropyLoss(ignore_index=0)\n",
    "opt = Adam(model.parameters(), lr=1e-3)\n",
    "print('number of parameters:', sum(p.numel() for p in model.parameters())/1e6, 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_downsampled_path_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from checkpoint\n",
    "from_epoch = 40\n",
    "if from_epoch > 0:\n",
    "    checkpoint = torch.load(f'checkpoint/{from_epoch}.pt')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    opt.load_state_dict(checkpoint['opt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:56<00:00,  2.56it/s, batch=290, gpu_temp=62, loss=1.13] \n",
      "100%|██████████| 1023/1023 [00:11<00:00, 87.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'value': 12, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'value': 24, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'value': 31, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'value': 36, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:01<00:00,  2.46it/s, batch=290, gpu_temp=57, loss=0.802]\n",
      "100%|██████████| 1023/1023 [00:10<00:00, 95.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'value': 12, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'value': 19, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'value': 24, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:03<00:00,  2.42it/s, batch=290, gpu_temp=57, loss=0.845]\n",
      "100%|██████████| 1023/1023 [00:10<00:00, 97.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'value': 8, 'type': 'pitch'}, {'value': 16, 'type': 'velocity'}, {'value': 20, 'type': 'pitch'}, {'value': 16, 'type': 'velocity'}, {'value': 36, 'type': 'pitch'}, {'value': 18, 'type': 'velocity'}, {'value': 39, 'type': 'pitch'}, {'value': 16, 'type': 'velocity'}, {'value': 43, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:05<00:00,  2.40it/s, batch=290, gpu_temp=62, loss=0.881]\n",
      "100%|██████████| 1023/1023 [00:10<00:00, 95.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'value': 27, 'type': 'pitch'}, {'value': 14, 'type': 'velocity'}, {'value': 31, 'type': 'pitch'}, {'value': 15, 'type': 'velocity'}, {'value': 34, 'type': 'pitch'}, {'value': 16, 'type': 'velocity'}, {'value': 39, 'type': 'pitch'}, {'value': 15, 'type': 'velocity'}, {'value': 46, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:09<00:00,  2.32it/s, batch=290, gpu_temp=62, loss=0.967]\n",
      "100%|██████████| 1023/1023 [00:10<00:00, 94.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'value': 32, 'type': 'pitch'}, {'value': 14, 'type': 'velocity'}, {'type': 'next_frame'}, {'value': 44, 'type': 'pitch'}, {'value': 12, 'type': 'velocity'}, {'value': 48, 'type': 'pitch'}, {'value': 16, 'type': 'velocity'}, {'value': 55, 'type': 'pitch'}, {'value': 15, 'type': 'velocity'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:13<00:00,  2.25it/s, batch=290, gpu_temp=61, loss=1.03] \n",
      "100%|██████████| 1023/1023 [00:11<00:00, 90.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'value': 27, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 34, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:15<00:00,  2.21it/s, batch=290, gpu_temp=63, loss=1.16] \n",
      "100%|██████████| 1023/1023 [00:13<00:00, 78.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'value': 12, 'type': 'pitch'}, {'value': 19, 'type': 'velocity'}, {'value': 24, 'type': 'pitch'}, {'value': 20, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 24, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:22<00:00,  2.10it/s, batch=290, gpu_temp=63, loss=0.883]\n",
      "100%|██████████| 1023/1023 [00:12<00:00, 82.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'value': 32, 'type': 'pitch'}, {'value': 21, 'type': 'velocity'}, {'value': 55, 'type': 'pitch'}, {'value': 22, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 36, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:22<00:00,  2.10it/s, batch=290, gpu_temp=63, loss=1.1]  \n",
      "100%|██████████| 1023/1023 [00:12<00:00, 81.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'value': 24, 'type': 'pitch'}, {'value': 10, 'type': 'velocity'}, {'value': 36, 'type': 'pitch'}, {'value': 10, 'type': 'velocity'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 24, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:25<00:00,  2.06it/s, batch=290, gpu_temp=58, loss=0.805]\n",
      "100%|██████████| 1023/1023 [00:12<00:00, 83.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:20<00:00,  2.13it/s, batch=290, gpu_temp=64, loss=0.98] \n",
      "100%|██████████| 1023/1023 [00:12<00:00, 83.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'value': 22, 'type': 'pitch'}, {'value': 16, 'type': 'velocity'}, {'value': 38, 'type': 'pitch'}, {'value': 17, 'type': 'velocity'}, {'value': 41, 'type': 'pitch'}, {'value': 15, 'type': 'velocity'}, {'value': 46, 'type': 'pitch'}, {'value': 19, 'type': 'velocity'}, {'value': 50, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:21<00:00,  2.12it/s, batch=290, gpu_temp=58, loss=0.797]\n",
      "100%|██████████| 1023/1023 [00:12<00:00, 82.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'value': 27, 'type': 'pitch'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:21<00:00,  2.12it/s, batch=290, gpu_temp=62, loss=1.06] \n",
      "100%|██████████| 1023/1023 [00:12<00:00, 82.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:12<00:00,  2.26it/s, batch=290, gpu_temp=62, loss=1.07] \n",
      "100%|██████████| 1023/1023 [00:11<00:00, 89.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}, {'type': 'next_frame'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 65/300 [00:34<02:03,  1.90it/s, batch=60, gpu_temp=60, loss=0.884]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;66;03m# print the loss to tqdm\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         tq\u001b[38;5;241m.\u001b[39mset_postfix(batch \u001b[38;5;241m=\u001b[39m i, loss\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem(), gpu_temp\u001b[38;5;241m=\u001b[39mtemp_control\u001b[38;5;241m.\u001b[39mget_temp())\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(loss):\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss is NaN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m inference(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output/output_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1024\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pianogen import gpu_temp_control\n",
    "\n",
    "temp_control = gpu_temp_control.GPUTempControl(64,3)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "crit.to(device)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(from_epoch+1,100):\n",
    "    tq = tqdm(dl)\n",
    "    for i, batch in enumerate(tq):\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        opt.zero_grad()\n",
    "        out = model(batch['indices'][:,:-1], batch['pos'])\n",
    "        loss = crit((out+batch['output_mask']).transpose(1,2), batch['indices'][:,1:])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        temp_control.cooldown()\n",
    "        if i % 10 == 0:\n",
    "            # print the loss to tqdm\n",
    "            tq.set_postfix(batch = i, loss= loss.item(), gpu_temp=temp_control.get_temp())\n",
    "                    \n",
    "        if torch.isnan(loss):\n",
    "            raise ValueError(\"Loss is NaN\")\n",
    "    \n",
    "    inference(f'./output/output_{epoch}_{i}.mid', 1024)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save({'model':model.state_dict(), 'opt':opt.state_dict()}, f'checkpoint/{epoch}.pt')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "prompt: [{'type': 'start'}, {'type': 'pitch', 'value': 32}, {'type': 'velocity', 'value': 14}, {'type': 'next_frame'}, {'type': 'pitch', 'value': 44}, {'type': 'velocity', 'value': 12}, {'type': 'pitch', 'value': 48}, {'type': 'velocity', 'value': 16}, {'type': 'pitch', 'value': 55}, {'type': 'velocity', 'value': 15}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1610/1610 [00:19<00:00, 84.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'type': 'start'}, {'type': 'pitch', 'value': 32}, {'type': 'velocity', 'value': 14}, {'type': 'next_frame'}, {'type': 'pitch', 'value': 44}, {'type': 'velocity', 'value': 12}, {'type': 'pitch', 'value': 48}, {'type': 'velocity', 'value': 16}, {'type': 'pitch', 'value': 55}, {'type': 'velocity', 'value': 15}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#inference('output/test.mid', 512,pr_ds.get_piano_roll(53548).slice(0, 32))\n",
    "from pianogen.data.pianoroll import PianoRoll\n",
    "model.to(device)\n",
    "inference('output/test.mid', 2000,PianoRoll.from_midi(r\"W:\\music\\piano-music-gen\\output\\output_35_299.mid\").slice(32*0,32*8))\n",
    "#inference('output/test.mid', 4000,pr_ds.get_piano_roll(2150).slice(32*0,32*12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle.remove()\n",
    "handle = model.in_local_attention.register_backward_hook(lambda m, g_in, g_out: print('in_local_attention', g_in[0].norm(dim=(0,2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_local_attention tensor([ 2.8973,  0.8830,  0.7586,  0.9899,  1.1048,  1.2402,  0.3792,  0.6488,\n",
      "         1.6528,  2.7425,  0.4552,  1.5836,  1.0128,  4.0604,  0.6707,  2.0891,\n",
      "         0.5262,  0.5684,  2.6314,  0.4023,  1.3787,  0.5873,  0.9673,  0.5430,\n",
      "         1.6225,  0.3887,  3.4039,  1.1779,  2.0503,  1.2313,  0.4384,  1.0173,\n",
      "         0.5497,  0.2947,  1.5697,  0.3889,  3.1795,  0.6917,  0.8305,  2.3320,\n",
      "         0.7165,  4.5779,  4.4148,  2.6414,  3.2237,  3.0840,  1.4059,  0.7477,\n",
      "         6.2199,  6.4681, 18.2421,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randint(0,10,(1, 220),dtype=torch.long).to(device)\n",
    "model(inp, torch.arange(220+1).unsqueeze(0).to(device))[0,50].norm().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ 0.0193,  0.0189,  0.0729,  0.0536,  0.1458,  0.0867,  0.1135,  0.7866,\n",
    "         0.1798,  0.0767,  0.0629,  0.0755,  0.1229,  0.1874,  0.6108,  0.1180,\n",
    "         0.1461,  0.0984,  0.0650,  0.1149,  0.3938,  0.2112,  0.1433,  0.3247,\n",
    "         0.1211,  0.1318,  0.2227,  0.1505,  0.3462,  0.1255,  0.0516,  0.2467,\n",
    "         0.2044,  0.4414,  0.1183,  0.4642,  0.1468,  0.0673,  0.0795,  0.6533,\n",
    "         0.2189,  0.1100,  0.1983,  0.2572,  0.3179,  0.1389,  0.6460,  0.0662,\n",
    "         0.1327,  0.1566,  0.5608,  0.0544,  0.3800,  0.3710,  0.1071,  0.0769,\n",
    "         0.1528,  0.2218,  0.0826,  0.0729,  0.0932,  0.1366,  0.2292,  0.3016,\n",
    "         0.3495,  0.9662,  0.0683,  0.1068,  0.3928,  0.4896,  0.2337,  0.1346,\n",
    "         0.8395,  0.2339,  0.1197,  0.9997,  0.2210,  0.3909,  0.1135,  0.1822,\n",
    "         0.3711,  0.2440,  0.0881,  0.1852,  0.1072,  0.0451,  0.0846,  0.1209,\n",
    "         0.1635,  0.4193,  0.0510,  0.0800,  0.1212,  0.2231,  0.1077,  0.1427,\n",
    "         0.1932,  0.1705,  0.3363,  0.3363,  0.2017,  0.1830,  0.2525,  0.4927,\n",
    "         0.6330,  0.5120,  0.2838,  1.1671,  0.7589,  1.1129,  1.9647,  1.1941,\n",
    "         0.7201,  0.3712,  0.3980,  0.5747,  0.9515,  2.6499,  0.3535,  2.9585,\n",
    "         0.5410,  0.7637,  0.5093,  1.4005,  3.1254,  2.2679,  1.5576,  1.8914,\n",
    "         2.9836, 13.3045])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp 10.0\n"
     ]
    }
   ],
   "source": [
    "temp(torch.randn(10,10)).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticks per beat: 480\n",
       "max tick: 0\n",
       "tempo changes: 1\n",
       "time sig: 0\n",
       "key sig: 0\n",
       "markers: 0\n",
       "lyrics: False\n",
       "instruments: 1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.ds.get_piano_roll(10).to_midi('output/test.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n"
     ]
    }
   ],
   "source": [
    "for i in range(1330,3000):\n",
    "    print(i)\n",
    "    pr = ds.ds.get_piano_roll(i)\n",
    "    l = []\n",
    "    for i in range(5):\n",
    "        l.append(pr.notes[i].pitch)\n",
    "    if len( {36, 48, 52, 55, 62} - set(l)) < 2:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36, 43, 48, 52, 55]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticks per beat: 480\n",
       "max tick: 0\n",
       "tempo changes: 1\n",
       "time sig: 0\n",
       "key sig: 0\n",
       "markers: 0\n",
       "lyrics: False\n",
       "instruments: 1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.to_midi('output/test.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'戰旗'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "random.choice(['隨單','戰旗'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
